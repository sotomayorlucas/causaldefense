# ðŸš€ CausalDefend Training Scripts

Scripts para entrenar los modelos de CausalDefend desde cero.

## ðŸ“‹ DescripciÃ³n

Este directorio contiene los scripts necesarios para:
1. **Generar datasets sintÃ©ticos** (para pruebas rÃ¡pidas)
2. **Importar datasets externos** (StreamSpot, DARPA TC, etc.)
3. **Entrenar el detector APT** (GAT+GRU)
4. **Entrenar el CI tester** (Neural Conditional Independence)
5. **Pipeline completo automatizado**

---

## ðŸŒŸ NUEVO: Usar Datasets Reales

### OpciÃ³n Recomendada: StreamSpot (~500 MB)

```powershell
# 1. Descargar StreamSpot (automÃ¡tico)
python scripts\download_streamspot.py

# 2. Importar al formato de CausalDefend
python scripts\import_external_dataset.py `
  --dataset streamspot `
  --input data\external\streamspot `
  --output data\processed\streamspot `
  --max-graphs 100

# 3. Dividir en train/val/test
python scripts\split_dataset.py `
  --input data\processed\streamspot `
  --output data\processed\streamspot_split

# 4. Entrenar con datos reales
python scripts\train_detector.py `
  --data data\processed\streamspot_split `
  --epochs 20 `
  --output models\streamspot_detector.ckpt

# 5. Evaluar
python examples\test_detector_advanced.py `
  --checkpoint models\streamspot_detector.ckpt `
  --data data\processed\streamspot_split\test
```

**Resultados Esperados** (segÃºn paper):
- F1-Score: ~0.90
- Precision: ~0.92
- Recall: ~0.89

ðŸ“š **MÃ¡s informaciÃ³n**: Ver [EXTERNAL_DATASETS.md](../docs/datasets/EXTERNAL_DATASETS.md)

---

## ðŸŽ¯ Quick Start (Modo RÃ¡pido - Datos SintÃ©ticos)

Para entrenar rÃ¡pidamente con un dataset pequeÃ±o (ideal para testing):

```bash
# Entrenar TODO (5-10 minutos en CPU)
python scripts/train_all.py --mode quick

# O paso por paso:
python scripts/prepare_dataset.py --num-benign 100 --num-attack 100
python scripts/train_detector.py --epochs 5 --batch-size 16
python scripts/train_ci_tester.py --epochs 3 --batch-size 16
```

**Resultado:**
- âœ… Dataset: 200 grafos (100 benignos, 100 ataques)
- âœ… Detector: 5 epochs (~3 min)
- âœ… CI Tester: 3 epochs (~2 min)
- âœ… Modelos guardados en `models/`

---

## ðŸ­ ProducciÃ³n (Modo Completo)

Para entrenar con dataset completo (producciÃ³n):

```bash
# Entrenar TODO (1-2 horas en CPU, 15-30 min en GPU)
python scripts/train_all.py --mode full

# O paso por paso:
python scripts/prepare_dataset.py --num-benign 500 --num-attack 500
python scripts/train_detector.py --epochs 100 --batch-size 32 --gpus 1
python scripts/train_ci_tester.py --epochs 50 --batch-size 64 --gpus 1
```

**Resultado:**
- âœ… Dataset: 1000 grafos (500 benignos, 500 ataques)
- âœ… Detector: 100 epochs (~45 min en GPU)
- âœ… CI Tester: 50 epochs (~30 min en GPU)
- âœ… MÃ©tricas objetivo: F1 > 0.95

---

## ðŸ“œ Scripts Disponibles

### 1. `prepare_dataset.py`

Genera datasets sintÃ©ticos de grafos de proveniencia con patrones de ataque APT.

**Uso:**
```bash
python scripts/prepare_dataset.py \
    --output data/processed \
    --num-benign 500 \
    --num-attack 500 \
    --avg-nodes 150 \
    --seed 42
```

**Argumentos:**
- `--output`: Directorio de salida (default: `data/processed`)
- `--num-benign`: NÃºmero de grafos benignos (default: 500)
- `--num-attack`: NÃºmero de grafos con ataques (default: 500)
- `--avg-nodes`: Promedio de nodos por grafo (default: 150)
- `--seed`: Semilla aleatoria (default: 42)

**Output:**
```
data/processed/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ graph_0.pkl
â”‚   â”œâ”€â”€ features_0.npy
â”‚   â”œâ”€â”€ label_0.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ val/
â””â”€â”€ test/
```

**Patrones de Ataque Incluidos:**
1. **Phishing** (15%): Email â†’ Browser â†’ Malware
2. **Credential Dump** (20%): Process â†’ LSASS â†’ Credentials
3. **Lateral Movement** (18%): PSExec â†’ Remote Host
4. **Data Exfiltration** (22%): Search â†’ Compress â†’ C2
5. **Privilege Escalation** (25%): Exploit â†’ Kernel â†’ Admin

---

### 2. `train_detector.py`

Entrena el modelo APTDetector (GAT+GRU) para detecciÃ³n de anomalÃ­as.

**Uso:**
```bash
python scripts/train_detector.py \
    --data data/processed \
    --epochs 100 \
    --batch-size 32 \
    --learning-rate 0.001 \
    --hidden-channels 128 \
    --num-heads 8 \
    --num-layers 3 \
    --gpus 1
```

**Argumentos:**
- `--data`: Directorio de datos (default: `data/processed`)
- `--output`: Directorio de checkpoints (default: `models`)
- `--epochs`: NÃºmero de epochs (default: 100)
- `--batch-size`: TamaÃ±o de batch (default: 32)
- `--learning-rate`: Learning rate (default: 0.001)
- `--hidden-channels`: Canales ocultos GAT (default: 128)
- `--num-heads`: Cabezas de atenciÃ³n (default: 8)
- `--num-layers`: Capas GAT (default: 3)
- `--gpus`: NÃºmero de GPUs (default: 0 = CPU)

**Output:**
```
models/
â”œâ”€â”€ detector.ckpt                    # Modelo final
â”œâ”€â”€ detector-epoch=XX-val_loss=Y.ckpt  # Mejores checkpoints
â””â”€â”€ ...

logs/
â””â”€â”€ apt_detector/
    â””â”€â”€ version_0/
        â””â”€â”€ events.out.tfevents.*    # TensorBoard logs
```

**MÃ©tricas Objetivo:**
- âœ… **F1-Score:** > 0.95
- âœ… **Precision:** > 0.93
- âœ… **Recall:** > 0.92
- âœ… **Val Loss:** < 0.1

**Visualizar Entrenamiento:**
```bash
tensorboard --logdir logs/apt_detector
# Abrir: http://localhost:6006
```

---

### 3. `train_ci_tester.py`

Entrena el Neural CI Tester para tests de independencia condicional.

**Uso:**
```bash
python scripts/train_ci_tester.py \
    --data data/processed \
    --epochs 50 \
    --batch-size 64 \
    --num-samples 10000 \
    --learning-rate 0.001 \
    --hidden-dim 128 \
    --num-layers 4 \
    --gpus 1
```

**Argumentos:**
- `--data`: Directorio de datos (default: `data/processed`)
- `--output`: Directorio de checkpoints (default: `models`)
- `--epochs`: NÃºmero de epochs (default: 50)
- `--batch-size`: TamaÃ±o de batch (default: 64)
- `--num-samples`: Triplets (X,Y,Z) a generar (default: 10000)
- `--learning-rate`: Learning rate (default: 0.001)
- `--hidden-dim`: DimensiÃ³n oculta (default: 128)
- `--num-layers`: NÃºmero de capas (default: 4)
- `--gpus`: NÃºmero de GPUs (default: 0 = CPU)

**Output:**
```
models/
â”œâ”€â”€ ci_tester.ckpt                    # Modelo final
â”œâ”€â”€ ci_tester-epoch=XX-val_loss=Y.ckpt  # Mejores checkpoints
â””â”€â”€ ...
```

**MÃ©tricas Objetivo:**
- âœ… **Accuracy:** > 0.85
- âœ… **Val Loss:** < 0.3

---

### 4. `train_all.py`

Pipeline automatizado que ejecuta todo el entrenamiento secuencialmente.

**Uso:**
```bash
# Modo rÃ¡pido (testing)
python scripts/train_all.py --mode quick

# Modo completo (producciÃ³n)
python scripts/train_all.py --mode full

# Con opciones de skip
python scripts/train_all.py --mode quick --skip-dataset  # Usar dataset existente
python scripts/train_all.py --mode full --skip-ci-tester  # Solo entrenar detector
```

**Modos:**

| Modo | Grafos | Detector Epochs | CI Epochs | Tiempo (CPU) | Tiempo (GPU) |
|------|--------|----------------|-----------|--------------|--------------|
| `quick` | 200 | 5 | 3 | ~10 min | ~3 min |
| `full` | 1000 | 100 | 50 | ~2 horas | ~30 min |

**Proceso:**
1. âœ… Genera dataset sintÃ©tico
2. âœ… Entrena APT Detector
3. âœ… Entrena CI Tester
4. âœ… Valida modelos
5. âœ… Genera reporte

---

## ðŸ“Š ValidaciÃ³n de Modelos

DespuÃ©s del entrenamiento, validar que los modelos funcionan:

```bash
# Verificar que los checkpoints existen
ls -lh models/

# DeberÃ­a mostrar:
# detector.ckpt       (~50-100 MB)
# ci_tester.ckpt      (~20-40 MB)

# Ejecutar demo completo
python examples/complete_detection.py

# O demo bÃ¡sico
python examples/demo_basico.py
```

---

## ðŸ› Troubleshooting

### Error: "No graphs found"
```bash
# SoluciÃ³n: Generar dataset primero
python scripts/prepare_dataset.py
```

### Error: "CUDA out of memory"
```bash
# SoluciÃ³n 1: Reducir batch size
python scripts/train_detector.py --batch-size 16

# SoluciÃ³n 2: Usar CPU
python scripts/train_detector.py --gpus 0
```

### Error: "NumPy warnings"
```bash
# SoluciÃ³n: Reinstalar NumPy con wheel precompilada
pip uninstall numpy -y
pip install --only-binary :all: numpy
```

### Warning: "Low F1-score"
Si despuÃ©s del entrenamiento el F1 < 0.90:

1. **Aumentar epochs:**
   ```bash
   python scripts/train_detector.py --epochs 200
   ```

2. **Aumentar dataset:**
   ```bash
   python scripts/prepare_dataset.py --num-benign 1000 --num-attack 1000
   ```

3. **Ajustar arquitectura:**
   ```bash
   python scripts/train_detector.py --hidden-channels 256 --num-layers 4
   ```

---

## ðŸ“ˆ MÃ©tricas Esperadas

### APT Detector (despuÃ©s de 100 epochs)
```
Epoch 100/100
train_loss: 0.042
train_acc: 0.978
val_loss: 0.055
val_acc: 0.963
âœ“ F1-Score: 0.95+
```

### CI Tester (despuÃ©s de 50 epochs)
```
Epoch 50/50
train_loss: 0.198
train_acc: 0.891
val_loss: 0.245
val_acc: 0.867
âœ“ Accuracy: 0.85+
```

---

## ðŸ”„ Re-entrenar Modelos

Si necesitas re-entrenar con nuevos datos:

```bash
# 1. Limpiar modelos anteriores
rm -rf models/*.ckpt logs/*

# 2. Generar nuevo dataset
python scripts/prepare_dataset.py --num-benign 1000 --num-attack 1000

# 3. Re-entrenar
python scripts/train_all.py --mode full
```

---

## ðŸŽ“ Siguiente Nivel: Dataset Real (DARPA TC)

Para usar el dataset real DARPA TC en lugar de sintÃ©tico:

1. **Descargar DARPA TC:**
   ```bash
   # OpciÃ³n 1: Desde Google Drive
   wget https://drive.google.com/file/d/DARPA_TC_DATASET_ID
   
   # OpciÃ³n 2: Desde repositorio oficial
   git clone https://github.com/darpa-i2o/Transparent-Computing
   ```

2. **Modificar `prepare_dataset.py`:**
   ```python
   # Agregar soporte para parsear logs DARPA TC
   # Ver: src/data/provenance_parser.py (ya tiene soporte)
   ```

3. **Entrenar con datos reales:**
   ```bash
   python scripts/prepare_dataset_darpa.py --input data/raw/darpa_tc
   python scripts/train_all.py --mode full
   ```

---

## ðŸ“š Referencias

- **Paper Original:** CausalDefend (ver `causaldefend.tex`)
- **Arquitectura:** `docs/ARCHITECTURE.md`
- **API:** `docs/API.md`
- **Deployment:** `DEPLOYMENT.md`

---

## âœ… Checklist de Entrenamiento

- [ ] Dataset generado (`data/processed/`)
- [ ] Detector entrenado (`models/detector.ckpt`)
- [ ] CI Tester entrenado (`models/ci_tester.ckpt`)
- [ ] F1-Score > 0.95
- [ ] CI Accuracy > 0.85
- [ ] Demo funciona sin errores
- [ ] TensorBoard logs generados

Â¡Una vez completado, tu sistema CausalDefend estÃ¡ listo para detectar APTs! ðŸŽ‰
