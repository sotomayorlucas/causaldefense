# CausalDefend: Explainable and Compliant APT Detection

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.1+](https://img.shields.io/badge/PyTorch-2.1+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

**CausalDefend** integrates structural causal models with temporal Graph Neural Networks to provide accurate APT detection with causally-grounded explanations and calibrated uncertainty quantification. Designed for EU AI Act compliance and production deployment in Security Operations Centers (SOCs).

## ğŸ¯ Key Features

- **ğŸ§  Causal Explanations**: Not just what was detected, but *why* the attack succeeded
- **ğŸ“Š Calibrated Uncertainty**: Conformal prediction with finite-sample coverage guarantees
- **âš–ï¸ EU AI Act Compliant**: Built-in explainability, audit logs, and human oversight
- **ğŸš€ Scalable**: Handles million-node provenance graphs via hierarchical architecture
- **ğŸ“ Research-Backed**: Based on peer-reviewed methods (USENIX Security, NDSS, CCS)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CausalDefend Pipeline                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  1. Provenance Graph Construction                            â”‚
â”‚     â””â”€> Parse system logs (ETW/auditd) â†’ Temporal graphs    â”‚
â”‚                                                               â”‚
â”‚  2. Spatio-Temporal Detection (GAT + GRU)                    â”‚
â”‚     â””â”€> Multi-head attention + Temporal dynamics             â”‚
â”‚                                                               â”‚
â”‚  3. Scalable Causal Discovery (if anomalous)                 â”‚
â”‚     â”œâ”€> Tier 1: Graph Reduction (90-95% compression)        â”‚
â”‚     â”œâ”€> Tier 2: Neural CI Tests (O(1) inference)            â”‚
â”‚     â””â”€> Tier 3: PC-Stable + MITRE ATT&CK priors             â”‚
â”‚                                                               â”‚
â”‚  4. Uncertainty Quantification                                â”‚
â”‚     â””â”€> Conformal prediction with adaptive calibration       â”‚
â”‚                                                               â”‚
â”‚  5. Explanation Generation                                    â”‚
â”‚     â””â”€> Attack narratives + counterfactuals                  â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Installation

### Prerequisites

- Python 3.10 or higher
- CUDA 11.8+ (for GPU acceleration)
- PostgreSQL 14+
- Redis 7+

### Quick Start

```bash
# Clone repository
git clone https://github.com/causaldefend/causaldefend.git
cd causaldefend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install package in development mode
pip install -e .

# Download spaCy model for narrative generation
python -m spacy download en_core_web_sm

# Setup database
createdb causaldefend
alembic upgrade head

# Start Redis
redis-server

# Run tests
pytest tests/
```

### Docker Installation

```bash
# Build and start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Access API at http://localhost:8000
```

## ğŸš€ Usage

### Complete Detection Example

```python
from pathlib import Path
from causaldefend.pipeline import create_default_pipeline

# Initialize pipeline
pipeline = create_default_pipeline(
    detector_checkpoint=Path("models/detector.ckpt"),
    ci_tester_checkpoint=Path("models/ci_tester.ckpt"),
    critical_assets=["DatabaseServer", "DomainController"]
)

# Process security alert
result = pipeline.process_alert(
    log_data=open("logs/system.log").read(),
    log_format="auditd",
    user_id="analyst_001"
)

# Check results
if result.anomaly_detected:
    print(f"ğŸš¨ APT Detected! Score: {result.anomaly_score:.2f}")
    
    # Display attack chains
    for chain in result.attack_chains:
        print(f"Attack chain: {' â†’ '.join(chain)}")
    
    # Display explanations
    for explanation in result.explanations:
        print(explanation.narrative)
        print(f"Critical nodes: {explanation.critical_nodes}")
        
    # Check if human review needed
    if result.should_escalate:
        print("âš ï¸  Low confidence - escalating to analyst")
else:
    print("âœ“ No anomalies detected")

# Submit feedback
pipeline.process_feedback(
    audit_log_id=result.audit_log_id,
    true_label=1,  # Confirmed attack
    feedback_text="Lateral movement attack confirmed"
)
```

### API Server

```bash
# Start FastAPI server
causaldefend-serve --host 0.0.0.0 --port 8000

# Or with uvicorn directly
uvicorn causaldefend.api.main:app --reload
```

### Training

```bash
# Train GAT+GRU detector
causaldefend-train \
    --data-path /path/to/darpa_tc \
    --config config/train_config.yaml \
    --gpus 1

# Train with MLflow tracking
causaldefend-train \
    --config config/train_config.yaml \
    --tracking-uri http://localhost:5000
```

### Pipeline Processing

```bash
# Process single provenance graph
causaldefend-pipeline \
    --input logs/system_audit.json \
    --output results/

# Batch processing
causaldefend-pipeline \
    --input-dir logs/ \
    --output-dir results/ \
    --batch-size 32
```

### Python API

```python
from causaldefend import CausalDefendPipeline
from causaldefend.data import ProvenanceParser

# Initialize pipeline
pipeline = CausalDefendPipeline.from_pretrained("models/causaldefend-v1")

# Parse logs
parser = ProvenanceParser()
graph = parser.parse_logs("system_audit.log")

# Detect and explain
result = pipeline.process_alert(graph)

print(f"Malicious: {result.is_malicious}")
print(f"Confidence: {result.confidence:.3f}")
print(f"Attack Narrative: {result.attack_narrative}")
print(f"MITRE Techniques: {result.mitre_techniques}")

if result.should_escalate:
    print("âš ï¸ Escalating to Tier-3 analyst")
```

## ğŸ“Š Performance

| Dataset | F1 Score | Precision | Recall | TTD (seconds) |
|---------|----------|-----------|--------|---------------|
| DARPA TC E3 | 0.982 | 0.978 | 0.986 | 0.42 |
| DARPA OpTC | 0.971 | 0.965 | 0.977 | 0.51 |
| CICAPT-IIoT | 0.958 | 0.962 | 0.954 | 0.38 |

**Scalability**: Processes 1M-node provenance graphs in <1 hour (causal discovery included)

**Calibration**: Expected Calibration Error (ECE) < 0.05 across all datasets

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run specific test categories
pytest tests/unit/              # Unit tests
pytest tests/integration/       # Integration tests
pytest tests/performance/       # Performance benchmarks
pytest tests/security/          # Adversarial robustness

# Run with coverage
pytest --cov=causaldefend --cov-report=html

# Run slow tests
pytest -m slow

# Performance benchmarking
pytest tests/performance/test_scalability.py --benchmark-only
```

## ğŸ“š Documentation

Full documentation available at: https://causaldefend.readthedocs.io

- [Architecture Overview](docs/architecture.md)
- [API Reference](docs/api.md)
- [Training Guide](docs/training.md)
- [Deployment Guide](docs/deployment.md)
- [EU AI Act Compliance](docs/compliance.md)

## ğŸ”¬ Research

This work is based on our paper:

> **CausalDefend: Towards Explainable and Compliant APT Detection via Causal Graph Neural Networks with Uncertainty Quantification**

If you use CausalDefend in your research, please cite:

```bibtex
@inproceedings{causaldefend2025,
  title={CausalDefend: Towards Explainable and Compliant APT Detection via Causal Graph Neural Networks with Uncertainty Quantification},
  author={Anonymous Authors},
  booktitle={IEEE Conference on Security and Privacy},
  year={2025}
}
```

## ğŸ¤ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- DARPA Transparent Computing Program for datasets
- MITRE Corporation for ATT&CK framework
- PyTorch Geometric team for excellent graph neural network library
- causal-learn contributors for causal discovery tools

## ğŸ“§ Contact

- Email: team@causaldefend.ai
- Issues: https://github.com/causaldefend/causaldefend/issues
- Discussions: https://github.com/causaldefend/causaldefend/discussions

## âš ï¸ Disclaimer

CausalDefend is a research prototype. While designed for production deployment, thorough testing and validation are required before use in critical security infrastructure. The authors assume no liability for security incidents.
