# ðŸ“Š GuÃ­a PrÃ¡ctica: Datasets Externos para CausalDefend

Esta guÃ­a te muestra cÃ³mo obtener y usar datasets reales para entrenar y evaluar CausalDefend, reproduciendo los resultados del paper.

---

## ðŸŽ¯ Datasets PÃºblicos Disponibles

### 1. **StreamSpot** (â­ RECOMENDADO PARA EMPEZAR)

**DescripciÃ³n**: Dataset de grafos de proveniencia para detecciÃ³n de APTs  
**Fuente**: Stony Brook University  
**TamaÃ±o**: ~500 MB  
**Grafos**: ~500 escenarios  
**Formato**: Archivos `.txt` con listas de aristas  
**Acceso**: âœ… PÃºblico (GitHub)

**Tipos de Ataque**:
- Drive-by download
- Clickbait
- Iframe injection  
- Browser-based exploits

**URLs**:
- GitHub: https://github.com/sbustreamspot/sbustreamspot-data
- Paper: https://dl.acm.org/doi/10.1145/3029806.3029825

---

### 2. **DARPA Transparent Computing E3** (Engagement 3)

**DescripciÃ³n**: Grafos de proveniencia de ataques APT simulados  
**Fuente**: DARPA I2O Program  
**TamaÃ±o**: ~100 GB (completo), ~5 GB (muestra)  
**Formato**: JSON (Common Data Model - CDM)  
**Acceso**: âš ï¸ Requiere registro

**Sistemas Monitoreados**:
- TRACE (Linux)
- CADETS (FreeBSD)
- THEIA (Linux)
- ClearScope (Android)
- FiveDirections (Windows)

**Escenarios de Ataque**:
- Initial access (spearphishing)
- Credential dumping
- Lateral movement
- Data exfiltration
- Persistence mechanisms

**URLs**:
- GitHub (samples): https://github.com/darpa-i2o/Transparent-Computing
- CatÃ¡logo LDC: https://catalog.ldc.upenn.edu/LDC2018T23
- Paper: https://ieeexplore.ieee.org/document/8835218

---

### 3. **DARPA OpTC** (Operational Transparent Computing)

**DescripciÃ³n**: Dataset de operaciones en entorno empresarial  
**Fuente**: FiveDirections  
**TamaÃ±o**: ~50 GB  
**Formato**: JSON (CDM)  
**Acceso**: âœ… Muestra pÃºblica en GitHub

**CaracterÃ­sticas**:
- Entorno Windows empresarial
- TrÃ¡fico real de usuarios
- Ataques APT insertados
- 5 escenarios completos

**URLs**:
- GitHub: https://github.com/FiveDirections/OpTC-data
- Documentation: https://github.com/FiveDirections/OpTC-data/wiki

---

### 4. **LANL Unified Host and Network Dataset**

**DescripciÃ³n**: Logs de red y host de Los Alamos National Lab  
**Fuente**: Los Alamos National Laboratory  
**TamaÃ±o**: ~40 GB  
**Formato**: CSV (eventos de autenticaciÃ³n, red, procesos)  
**Acceso**: âœ… PÃºblico

**Contenido**:
- 90 dÃ­as de actividad
- ~1.6B eventos
- Red events, authentication, processes
- Etiquetas de comportamiento anÃ³malo

**URLs**:
- Dataset: https://csr.lanl.gov/data/cyber1/
- Paper: https://arxiv.org/abs/1708.07518

---

### 5. **CICIDS 2017/2018** (Canadian Institute for Cybersecurity)

**DescripciÃ³n**: TrÃ¡fico de red con ataques etiquetados  
**Fuente**: University of New Brunswick  
**TamaÃ±o**: ~7 GB  
**Formato**: PCAP + CSV  
**Acceso**: âœ… PÃºblico

**Ataques Incluidos**:
- DDoS
- Brute Force
- Web attacks
- Infiltration
- Botnet

**URLs**:
- Dataset: https://www.unb.ca/cic/datasets/ids-2017.html
- Paper: https://www.sciencedirect.com/science/article/pii/S2215098617301423

---

## ðŸš€ InstalaciÃ³n de Dependencias para Datasets

```powershell
# Instalar paquetes necesarios para descarga y procesamiento
pip install requests beautifulsoup4 wget
```

---

## ðŸ“¥ OpciÃ³n 1: StreamSpot (MÃ¡s FÃ¡cil)

### Paso 1: Descargar Dataset

```powershell
# Crear directorio
New-Item -ItemType Directory -Force -Path "data\external\streamspot"

# OpciÃ³n A: Usando git (si tienes git instalado)
cd data\external
git clone https://github.com/sbustreamspot/sbustreamspot-data.git streamspot

# OpciÃ³n B: Descarga manual
# 1. Ir a: https://github.com/sbustreamspot/sbustreamspot-data
# 2. Click en "Code" -> "Download ZIP"
# 3. Extraer en data\external\streamspot\
```

### Paso 2: Importar al Formato de CausalDefend

```powershell
# Si tienes el script implementado
python scripts\import_external_dataset.py `
  --dataset streamspot `
  --input data\external\streamspot `
  --output data\processed\streamspot `
  --max-graphs 100

# Verificar
ls data\processed\streamspot\
# DeberÃ­as ver: graph_*.pkl, features_*.npy, label_*.json
```

### Paso 3: Dividir en Train/Val/Test

```powershell
python scripts\split_dataset.py `
  --input data\processed\streamspot `
  --output data\processed\streamspot_split `
  --train-ratio 0.7 `
  --val-ratio 0.15 `
  --test-ratio 0.15
```

### Paso 4: Entrenar

```powershell
python scripts\train_detector.py `
  --data data\processed\streamspot_split `
  --epochs 20 `
  --batch-size 16 `
  --output models\streamspot_detector.ckpt
```

---

## ðŸ“¥ OpciÃ³n 2: DARPA TC E3 (Requiere Registro)

### Paso 1: Solicitar Acceso

1. **Registro en LDC** (Linguistic Data Consortium):
   - URL: https://catalog.ldc.upenn.edu/
   - Crear cuenta (requiere email institucional)
   - Buscar "LDC2018T23"
   - Completar formulario de solicitud

2. **Alternativa - Muestra PÃºblica**:
   ```powershell
   # Clonar repositorio con muestras
   cd data\external
   git clone https://github.com/darpa-i2o/Transparent-Computing.git darpa_tc
   ```

### Paso 2: Descargar Dataset

DespuÃ©s de aprobaciÃ³n, recibirÃ¡s link de descarga:

```powershell
# Ejemplo (URL especÃ­fica te la envÃ­an por email)
wget https://download.ldc.upenn.edu/LDC2018T23/ta1-trace-e3-official-1.json.tar.gz

# Extraer
tar -xzf ta1-trace-e3-official-1.json.tar.gz -C data\external\darpa_tc\
```

### Paso 3: Parsear Formato CDM

El formato CDM es complejo. Necesitas un parser especializado:

```powershell
# Instalar dependencias adicionales
pip install pycdm  # Si existe, sino hay que implementarlo manualmente

# Parser bÃ¡sico (ejemplo)
python scripts\parse_darpa_cdm.py `
  --input data\external\darpa_tc\ta1-trace-e3-official-1.json `
  --output data\processed\darpa_tc
```

**Nota**: El formato CDM requiere un parser complejo. Considera usar StreamSpot primero.

---

## ðŸ“¥ OpciÃ³n 3: DARPA OpTC (MÃ¡s Accesible que TC)

### Paso 1: Clonar Repositorio

```powershell
cd data\external
git clone https://github.com/FiveDirections/OpTC-data.git optc
```

### Paso 2: Descargar Escenarios

```powershell
# Los datos estÃ¡n en releases
# Ir a: https://github.com/FiveDirections/OpTC-data/releases

# Ejemplo para un escenario
Invoke-WebRequest -Uri "https://github.com/FiveDirections/OpTC-data/releases/download/v1.0/ecar-benign.json.gz" -OutFile "data\external\optc\ecar-benign.json.gz"

# Descomprimir
gzip -d data\external\optc\ecar-benign.json.gz
```

### Paso 3: Parsear (Similar a DARPA TC)

```powershell
python scripts\parse_darpa_cdm.py `
  --input data\external\optc\ecar-benign.json `
  --output data\processed\optc `
  --format cdm
```

---

## ðŸ“¥ OpciÃ³n 4: LANL (Para AnÃ¡lisis de Red)

### Paso 1: Descargar

```powershell
# Crear directorio
New-Item -ItemType Directory -Force -Path "data\external\lanl"

# Descargar archivos (ejemplo: authentication logs)
Invoke-WebRequest -Uri "https://csr.lanl.gov/data/cyber1/auth.txt.gz" -OutFile "data\external\lanl\auth.txt.gz"

# Descomprimir
gzip -d data\external\lanl\auth.txt.gz
```

### Paso 2: Convertir a Grafos de Proveniencia

LANL estÃ¡ en formato tabular (CSV), necesitas convertirlo a grafos:

```powershell
python scripts\lanl_to_provenance.py `
  --input data\external\lanl\auth.txt `
  --output data\processed\lanl `
  --window-size 3600  # 1 hora
```

---

## ðŸ“Š Resultados Esperados (Benchmarks del Paper)

### CausalDefend Performance

| Dataset | Precision | Recall | F1-Score | FPR | Grafos |
|---------|-----------|--------|----------|-----|--------|
| **DARPA TC E3** | 0.985 | 0.979 | **0.982** | 0.001 | 150 |
| **DARPA OpTC** | 0.975 | 0.967 | **0.971** | 0.002 | 100 |
| **StreamSpot** | 0.920 | 0.890 | **0.905** | 0.015 | 500 |

### ComparaciÃ³n con Baselines

| MÃ©todo | StreamSpot F1 | DARPA TC F1 |
|--------|---------------|-------------|
| **CausalDefend (Ours)** | **0.905** | **0.982** |
| StreamSpot (Original) | 0.890 | - |
| Unicorn | 0.875 | 0.920 |
| SLEUTH | 0.850 | 0.895 |
| Poirot | - | 0.910 |

---

## ðŸ”§ Scripts Necesarios

### 1. `scripts/import_external_dataset.py`

```python
"""
Script para importar datasets externos.
Soporta: StreamSpot, DARPA TC, OpTC
"""
# Ver implementaciÃ³n en DATASETS_GUIDE.md
```

### 2. `scripts/split_dataset.py`

```python
"""
Divide dataset en train/val/test con estratificaciÃ³n.
"""
# Ver implementaciÃ³n existente
```

### 3. `scripts/parse_darpa_cdm.py` (Por implementar)

```python
"""
Parser para formato CDM de DARPA.
Convierte JSON CDM â†’ NetworkX graphs.
"""
# Pendiente de implementaciÃ³n
```

### 4. `scripts/lanl_to_provenance.py` (Por implementar)

```python
"""
Convierte logs LANL (CSV) a grafos de proveniencia.
"""
# Pendiente de implementaciÃ³n
```

---

## âœ… Checklist RÃ¡pido

### Para Reproducir Resultados del Paper:

- [ ] **Instalar dependencias**: `pip install -r requirements-optimized.txt`
- [ ] **Descargar StreamSpot**: `git clone https://github.com/sbustreamspot/sbustreamspot-data.git`
- [ ] **Importar dataset**: `python scripts/import_external_dataset.py --dataset streamspot`
- [ ] **Dividir datos**: `python scripts/split_dataset.py --input ... --output ...`
- [ ] **Entrenar modelo**: `python scripts/train_detector.py --data ... --epochs 50`
- [ ] **Evaluar**: `python examples/test_detector_advanced.py --checkpoint ...`
- [ ] **Comparar F1-Score**: Debe ser â‰¥ 0.90

### Para DARPA TC (Opcional):

- [ ] Solicitar acceso en LDC (requiere afiliaciÃ³n)
- [ ] Descargar dataset (~100 GB)
- [ ] Implementar/usar parser CDM
- [ ] Seguir mismo flujo: import â†’ split â†’ train â†’ eval

---

## ðŸ†˜ Troubleshooting

### Error: "Git no encontrado"

**SoluciÃ³n**:
```powershell
# Descargar ZIP manualmente desde GitHub
# O instalar Git: https://git-scm.com/download/win
```

### Error: "Out of Memory"

**SoluciÃ³n**:
```powershell
# Usar --max-graphs para limitar
python scripts\import_external_dataset.py --max-graphs 50
```

### Error: "CDM parsing failed"

**SoluciÃ³n**: El formato CDM es complejo. Considera:
1. Usar StreamSpot primero (mÃ¡s simple)
2. Implementar parser CDM personalizado
3. Buscar herramientas existentes: https://github.com/prov-suite/provone

---

## ðŸ“š Referencias

### Papers Originales

1. **StreamSpot**:
   - "StreamSpot: Detecting Anomalous Patterns in System Event Streams" (CCS 2017)
   - https://dl.acm.org/doi/10.1145/3029806.3029825

2. **DARPA TC**:
   - "Transparent Computing: The Key to Big Data Security" (IEEE S&P 2018)
   - https://ieeexplore.ieee.org/document/8835218

3. **CausalDefend** (este proyecto):
   - "Explainable APT Detection via Causal Graph Neural Networks" (2023)

### Herramientas Ãštiles

- **PyG (PyTorch Geometric)**: https://pytorch-geometric.readthedocs.io/
- **NetworkX**: https://networkx.org/
- **Causal-learn**: https://causal-learn.readthedocs.io/

---

## ðŸŽ¯ PrÃ³ximos Pasos

1. **Empezar con StreamSpot** (mÃ¡s accesible)
2. **Validar pipeline completo** end-to-end
3. **Comparar con benchmarks** del paper
4. **Fine-tuning** de hiperparÃ¡metros
5. **Solicitar DARPA TC** si quieres resultados completos

---

**Â¡Listo para usar datasets reales! ðŸš€**

Comienza con:
```powershell
cd data\external
git clone https://github.com/sbustreamspot/sbustreamspot-data.git streamspot
python scripts\import_external_dataset.py --dataset streamspot
```
