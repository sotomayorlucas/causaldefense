# ğŸ§ª GuÃ­a de Pruebas de CausalDefend

Esta guÃ­a describe todas las formas de probar el sistema CausalDefend mÃ¡s allÃ¡ del demo bÃ¡sico.

---

## ğŸ“‹ Ãndice de Pruebas

1. **Demo BÃ¡sico** - IntroducciÃ³n rÃ¡pida al sistema
2. **EvaluaciÃ³n Avanzada** - Test set completo con mÃ©tricas
3. **ComparaciÃ³n de Ataques** - Diferentes tipos de APTs
4. **Dashboard Interactivo** - MÃ©tricas y recomendaciones
5. **Pruebas Personalizadas** - Crea tus propios tests

---

## 1. ğŸ¯ Demo BÃ¡sico (Ya ejecutado)

**PropÃ³sito**: Verificar que todos los componentes funcionan

```powershell
python examples\demo_basico.py
```

**QuÃ© muestra**:
- âœ… CreaciÃ³n de grafos de proveniencia
- âœ… Red neuronal de detecciÃ³n
- âœ… Descubrimiento de cadenas causales
- âœ… GeneraciÃ³n de explicaciones

**Tiempo**: ~30 segundos  
**Dificultad**: â­ BÃ¡sico

---

## 2. ğŸ”¬ EvaluaciÃ³n Avanzada

**PropÃ³sito**: Evaluar el detector en el test set completo

```powershell
python examples\test_detector_advanced.py
```

**QuÃ© hace**:
1. Carga el modelo entrenado (`models/detector.ckpt`)
2. EvalÃºa en 30 grafos del test set (16 ataques + 14 normales)
3. Calcula mÃ©tricas: Accuracy, Precision, Recall, F1
4. Muestra matriz de confusiÃ³n
5. Prueba con ataque sintÃ©tico
6. Identifica nodos mÃ¡s sospechosos

**Resultados Obtenidos**:
- âœ… **Accuracy**: 96.67%
- âœ… **Precision**: 100% (sin falsos positivos)
- âœ… **Recall**: 93.75% (15/16 ataques detectados)
- âœ… **F1 Score**: 96.77%

**Salida**:
- Archivo: `models/evaluation_results.json`
- MÃ©tricas detalladas guardadas

**Tiempo**: ~1 minuto  
**Dificultad**: â­â­ Intermedio

---

## 3. ğŸ­ ComparaciÃ³n de Tipos de Ataques

**PropÃ³sito**: Ver cÃ³mo se comporta el detector con diferentes familias APT

```powershell
python examples\compare_apt_detection.py
```

**Tipos de Ataques Probados**:
1. **Ransomware** (T1486) - CRÃTICO
   - Cifrado masivo de archivos
   - Score tÃ­pico: ~150+ (muy alto)
   - âœ… Siempre detectado

2. **Data Exfiltration** (T1041) - ALTO
   - Robo de datos sensibles
   - Score tÃ­pico: ~0.2 (bajo)
   - âš ï¸ DifÃ­cil de detectar (sigiloso)

3. **Lateral Movement** (T1021) - MEDIO
   - Movimiento entre hosts
   - Score tÃ­pico: ~11 (moderado)
   - âš ï¸ Puede pasar desapercibido

4. **Privilege Escalation** (T1068) - ALTO
   - Escalada a SYSTEM
   - Score tÃ­pico: ~1 (bajo)
   - âš ï¸ Requiere ajuste de threshold

5. **Persistence** (T1547) - MEDIO
   - Backdoors y autostart
   - Score tÃ­pico: ~35 (alto)
   - âœ… Generalmente detectado

6. **Cryptomining** (T1496) - BAJO
   - MinerÃ­a de criptomonedas
   - Score tÃ­pico: ~29 (alto)
   - âœ… FÃ¡cil de detectar

**Resultados**:
```
ğŸ”´ Ransomware         ğŸš¨ DETECTADO    Score: 157.08
ğŸŸ¡ Data Exfiltration  âœ“ No detectado  Score:   0.20
ğŸŸ¡ Lateral Movement   âœ“ No detectado  Score:  11.27
ğŸŸ¡ Privilege Escalat. âœ“ No detectado  Score:   1.05
ğŸŸ¡ Persistence        ğŸš¨ DETECTADO    Score:  35.17
ğŸŸ¢ Cryptomining       ğŸš¨ DETECTADO    Score:  29.36
ğŸŸ¢ Normal Activity    âœ“ No detectado  Score:   0.02
```

**Conclusiones**:
- âœ… Excelente contra ataques obvios/ruidosos
- âš ï¸ Necesita mejora para ataques sigilosos
- ğŸ’¡ Threshold actual: 15.59 (puede ajustarse)

**Tiempo**: ~30 segundos  
**Dificultad**: â­â­ Intermedio

---

## 4. ğŸ“Š Dashboard Interactivo

**PropÃ³sito**: VisualizaciÃ³n profesional de mÃ©tricas y recomendaciones

```powershell
python examples\dashboard.py
```

**Secciones del Dashboard**:

### âš™ï¸ Estado del Sistema
- Verifica componentes crÃ­ticos
- Estado: ğŸŸ¢ OPERACIONAL

### ğŸ“Š MÃ©tricas de Rendimiento
```
Accuracy   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 96.7%
Precision  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0%
Recall     [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ] 93.8%
F1 Score   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 96.8%
```

### ğŸ“ˆ Matriz de ConfusiÃ³n
```
              PREDICCIÃ“N
           Normal  Ataque
Real  N     14       0     â† Sin falsos positivos
      A      1      15     â† Solo 1 falso negativo
```

### ğŸ¯ Inteligencia de Amenazas
- Total amenazas: 16
- Detectadas: 15 (93.8%)
- No detectadas: 1 (6.2%)
- Nivel de riesgo: ğŸŸ¡ MEDIO

### âš–ï¸ Threshold de DetecciÃ³n
- Actual: 15.5967
- GuÃ­as para ajuste

### ğŸ’¡ Recomendaciones
- ActualizaciÃ³n de modelo
- Monitoreo continuo
- Respuesta a incidentes
- Mejora continua

**Tiempo**: 5 segundos  
**Dificultad**: â­ BÃ¡sico

---

## 5. ğŸ› ï¸ Crear Tus Propias Pruebas

### Ejemplo: Probar con un Grafo Personalizado

```python
import torch
from torch_geometric.data import Data
from models.spatiotemporal_detector import APTDetector

# 1. Cargar modelo
checkpoint = torch.load("models/detector.ckpt", map_location='cpu')
model = APTDetector(in_channels=64, hidden_channels=128, ...)
model.load_state_dict(checkpoint['state_dict'], strict=False)
model.eval()

# 2. Crear tu grafo
features = torch.randn(20, 64)  # 20 nodos, 64 features
edges = torch.tensor([[0,1,2], [1,2,3]], dtype=torch.long)
data = Data(x=features, edge_index=edges)

# 3. Detectar
with torch.no_grad():
    embedding, edge_probs = model(data.x, data.edge_index)
    # Calcular anomaly score...
```

---

## ğŸ“Š Resumen de Resultados

| Prueba | Resultado | Tiempo | Archivos Generados |
|--------|-----------|--------|--------------------|
| Demo BÃ¡sico | âœ… 4/4 tests OK | 30s | - |
| EvaluaciÃ³n Avanzada | âœ… 96.7% accuracy | 1min | `evaluation_results.json` |
| ComparaciÃ³n Ataques | âš ï¸ 50% detecciÃ³n | 30s | - |
| Dashboard | âœ… Sistema operacional | 5s | - |

---

## ğŸ¯ MÃ©tricas Finales del Sistema

### Test Set (30 grafos)
- **True Positives**: 15 ataques detectados
- **True Negatives**: 14 normales clasificados correctamente
- **False Positives**: 0 (Â¡perfecto!)
- **False Negatives**: 1 ataque perdido

### Rendimiento
- **Accuracy**: 96.67% - Excelente
- **Precision**: 100% - Sin falsas alarmas
- **Recall**: 93.75% - Alta cobertura
- **F1 Score**: 96.77% - Balance Ã³ptimo

### Tipos de Ataque
- **Obvios/Ruidosos**: 100% detecciÃ³n (Ransomware, Cryptomining)
- **Sigilosos**: 0-50% detecciÃ³n (Data Exfil, Lateral Movement)
- **Intermedios**: 50% detecciÃ³n (Persistence)

---

## ğŸ’¡ Recomendaciones de Uso

### Para Desarrollo
1. Ejecutar `test_detector_advanced.py` despuÃ©s de cada entrenamiento
2. Usar `compare_apt_detection.py` para validar nuevos tipos de ataque
3. Revisar `dashboard.py` antes de desplegar

### Para ProducciÃ³n
1. Configurar threshold basado en tolerancia a falsos positivos
2. Implementar re-entrenamiento periÃ³dico (cada 2-4 semanas)
3. Integrar con SIEM para alertas automÃ¡ticas
4. Mantener logs de detecciones para mejora continua

### Para InvestigaciÃ³n
1. Analizar el ataque no detectado (falso negativo)
2. Ajustar features para mejorar detecciÃ³n de ataques sigilosos
3. Probar con datos reales de auditorÃ­a
4. Implementar explicaciones causales completas

---

## ğŸš€ PrÃ³ximos Pasos

### Inmediato
- [x] Sistema base funcionando
- [x] Modelos entrenados
- [x] EvaluaciÃ³n completa
- [ ] Ajustar threshold para ataques sigilosos
- [ ] Documentar el ataque no detectado

### Corto Plazo (1-2 semanas)
- [ ] Integrar con fuentes de threat intelligence
- [ ] Implementar API REST para detecciÃ³n
- [ ] Crear pipeline automatizado
- [ ] Generar reportes ejecutivos

### Mediano Plazo (1-2 meses)
- [ ] Re-entrenar con mÃ¡s datos (1000+ grafos)
- [ ] Implementar ensemble de modelos
- [ ] Agregar detecciÃ³n temporal (secuencias de grafos)
- [ ] Desplegar en ambiente de producciÃ³n

---

## ğŸ“ Comandos RÃ¡pidos

```powershell
# Navegar al proyecto
cd C:\Users\lsotomayor\Desktop\causaldefense\causaldefend

# Ejecutar todas las pruebas
python examples\demo_basico.py
python examples\test_detector_advanced.py
python examples\compare_apt_detection.py
python examples\dashboard.py

# Ver resultados guardados
cat models\evaluation_results.json

# Re-entrenar (opcional)
python scripts\train_detector.py --epochs 20 --batch-size 16
```

---

## ğŸ† Estado del Proyecto

**CausalDefend v1.0** estÃ¡:
- âœ… Completamente funcional
- âœ… Bien evaluado (96.7% accuracy)
- âœ… Listo para demos
- âš ï¸ Necesita ajustes para ataques sigilosos
- ğŸš€ Preparado para producciÃ³n piloto

---

**DocumentaciÃ³n generada**: 29 de octubre de 2025  
**Ãšltima actualizaciÃ³n**: DespuÃ©s de entrenamiento completo
